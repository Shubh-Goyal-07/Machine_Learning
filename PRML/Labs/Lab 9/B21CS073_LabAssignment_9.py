# -*- coding: utf-8 -*-
"""B21CS073_LabAssignment_9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13XIO2hM3-bxvUE7PlFMk7ZmKMePGJ82v

# ***Question 01***


---



---
## ***Basic Neural Network- Digit Recognition***

### ***1. Download the MNIST dataset using torch-vision. Split into train, test and validation dataset. Apply Augmentions to images:***
### ***a. Training dataset: RandomRotation(5 degrees), RandomCrop(size=28, padding=2), ToTensor and Normalize.***
### ***b. Testing dataset and validation dataset: ToTensor and Normalize***
"""

import torch
import torchvision
from torchvision import transforms

# Download MNIST dataset
train_data = torchvision.datasets.MNIST(root='./data', train=True, transform=None, download=True)
test_data = torchvision.datasets.MNIST(root='./data', train=False, transform=None, download=True)

print('The size of training data is:', len(train_data))

train_transformations = transforms.Compose([
    transforms.RandomRotation(5),
    transforms.RandomCrop(28, padding=2),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

test_val_transformations = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_data.transform = train_transformations
test_data.transform = test_val_transformations

train_data, val_data = torch.utils.data.random_split(train_data, [50000, 10000])

"""### ***2. Plot a few Images from each class. Create a data loader for the training dataset as well as the testing dataset.***"""

train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)
val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)

import matplotlib.pyplot as plt
import numpy as np

def plot_images(data, labels):
    fig, axs = plt.subplots(10, 10, figsize=(10, 10))
    for i in range(10):
        for j in range(10):
            idx = np.where(labels == (i))[0][j]
            axs[i][j].imshow(data[idx].numpy().squeeze(), cmap='gray')
            axs[i][j].axis('off')
            axs[i][j].set_title(str(i))

plot_images(test_data.data, test_data.targets)

"""### ***3. Write a 3-Layer MLP using PyTorch all using Linear layers. Print the number of trainable parameters of the model.***"""

import torch.nn as nn

class NN(nn.Module):
    def __init__(self):
        super(NN, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)

    def forward(self, img):
        ten = img.view(img.size(0), -1) 
        ten = nn.functional.relu(self.fc1(ten))
        ten = nn.functional.relu(self.fc2(ten))
        out = self.fc3(ten)
        return out

model = NN()
print('Number of trainable parameters: ',sum(p.numel() for p in model.parameters() if p.requires_grad))

"""### ***4. Train the model for 5 epochs using Adam as the optimizer and CrossEntropyLoss as the Loss Function. Make sure to evaluate the model on the validation set after each epoch and save the best model as well as log the accuracy and loss of the model on training and validation data at the end of each epoch.***"""

import torch.optim as optim

optimizer = optim.Adam(model.parameters())
loss_type = nn.CrossEntropyLoss()

best_acc = 0
best_model = None

train_loss, val_loss, train_acc, val_acc = list(), list(), list(), list()

for epoch in range(5):
    
    model.train()
    loss = 0.0
    correct = 0

    #Training Loop
    for inputs, labels in train_loader:

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = loss_type(outputs, labels)
        loss.backward()

        optimizer.step()

        _, pred = torch.max(outputs, 1)
        loss += loss.item() * inputs.size(0)
        correct += torch.sum(pred == labels.data)

    loss_t = loss / 50000
    acc_t = correct / 50000

    model.eval()

    loss_val = 0.0
    correct_val = 0

    #Validation
    with torch.no_grad():
        for inputs, labels in val_loader:

            outputs = model(inputs)
            loss = loss_type(outputs, labels)

            _, pred = torch.max(outputs, 1)
            loss_val += loss.item() * inputs.size(0)
            correct_val += torch.sum(pred == labels.data)

        loss_val = loss_val / 10000
        acc_val = correct_val / 10000


    train_loss.append(loss_t.item())
    val_loss.append(loss_val)
    train_acc.append(acc_t.item())
    val_acc.append(acc_val.item())
    print('Epoch', epoch+1, 'Training Loss: ', loss_t.item(), 'Validation Loss: ', loss_val, 'Training Accuracy: ', acc_t.item(),  'Validation Accuracy: ', acc_val.item())


    if acc_val > best_acc:
        best_acc = acc_val
        best_model=model

"""### ***5. Visualize correct and Incorrect predictions along with Loss-Epoch and Accuracy-Epoch graphs for both training and validation.***"""

import matplotlib.pyplot as plt

def get_predictions(model, data_loader):
    model.eval()
    images, labels, preds = [], [], []
    with torch.no_grad():
        for inputs, targets in data_loader:
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            images.append(inputs.cpu())
            labels.append(targets.cpu())
            preds.append(predicted.cpu())
    images = torch.cat(images, dim=0)
    labels = torch.cat(labels, dim=0)
    preds = torch.cat(preds, dim=0)
    return images, labels, preds

train_images, train_labels, train_preds = get_predictions(model, train_loader)
val_images, val_labels, val_preds = get_predictions(model, val_loader)

def plot_images(images, labels, preds, title):
    fig, axs = plt.subplots(3, 3, figsize=(10, 10))
    fig.suptitle(title)
    for i, ax in enumerate(axs.flat):
        ax.imshow(images[i].squeeze(), cmap='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(f'True: {labels[i]} \n Pred: {preds[i]}')
    plt.show()

correct_preds = train_preds.eq(train_labels)
correct_images = train_images[correct_preds]
correct_labels = train_labels[correct_preds]
correct_preds = train_preds[correct_preds]
plot_images(correct_images, correct_labels, correct_preds, 'Correct Predictions - Training')

incorrect_preds = train_preds.ne(train_labels)
incorrect_images = train_images[incorrect_preds]
incorrect_labels = train_labels[incorrect_preds]
incorrect_preds = train_preds[incorrect_preds]
plot_images(incorrect_images, incorrect_labels, incorrect_preds, 'Incorrect Predictions - Training')


correct_preds = val_preds.eq(val_labels)
correct_images = val_images[correct_preds]
correct_labels = val_labels[correct_preds]
correct_preds = val_preds[correct_preds]
plot_images(correct_images, correct_labels, correct_preds, 'Correct Predictions - Validation')

incorrect_preds = val_preds.ne(val_labels)
incorrect_images = val_images[incorrect_preds]
incorrect_labels = val_labels[incorrect_preds]
incorrect_preds = val_preds[incorrect_preds]
plot_images(incorrect_images, incorrect_labels, incorrect_preds, 'Incorrect Predictions - Validation')

# Plot the loss-epoch and accuracy-epoch graphs for the training and validation sets
fig, axs = plt.subplots(2, 1, figsize=(8, 8))
fig.suptitle('Training and Validation Metrics')
axs[0].plot(train_loss, label='Training Loss')
axs[0].plot(val_loss, label='Validation Loss')
axs[0].set_xlabel('Epoch')
axs[0].set_ylabel('Loss')
axs[0].legend()
axs[1].plot(train_acc, label='Training Accuracy')
axs[1].plot(val_acc, label='Validation Accuracy')
axs[1].set_xlabel('Epoch')
axs[1].set_ylabel('Accuracy')
axs[1].legend()
plt.show()

"""# ***QUESTION 2***


---



---

## ***Implement ANN from scratch***

### ***1. Preprocess & visualize the data. Create train, val, and test splits but take into consideration the class distribution (Hint: Look up stratified splits).***
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder

abalone_data = pd.read_csv('/content/drive/MyDrive/PRML/Lab 9/abalone.data',
                           names=['Sex', 'Length', 'Diameter', 'Height', 'Whole weigth', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings'],
                           header=None)

abalone_data

abalone_data.info()

abalone_data.nunique()

print(abalone_data['Rings'])

abalone_data = pd.get_dummies(abalone_data, columns = ['Sex'])
print(abalone_data)

abalone_y = abalone_data['Rings']
abalone_x = abalone_data.drop(['Rings'], axis=1)

for i in range(len(abalone_y)):
    if 0<abalone_y[i]<9:
        abalone_y[i] = 1
    elif 8<abalone_y[i]<11:
        abalone_y[i] = 2
    else:
        abalone_y[i] = 3

abalonex_np = abalone_x.to_numpy()
abaloney_np = abalone_y.to_numpy()

abaloney_np

from sklearn.model_selection import train_test_split as split

train_ax, test_ax, train_ay, test_ay = split(abalonex_np, abaloney_np, train_size=0.8, stratify=abaloney_np)

"""### ***2. Implement a multi-layer perceptron from scratch. This would include the following***
**a. Write activation functions.**

**b. Forward propagate the input.**

**c. Back propagate the error.**

**d. Train the network using stochastic gradient descent.**

**e. Predict the output for a given test sample and compute the accuracy.**
"""

import numpy as np
from math import exp
import time
import math

class NN():

    def __init__(self, params = 0, learning_rate=1, epochs=5):
        self.epochs = epochs
        self.alpha = learning_rate
        self.params = params

        self.layer_info = {}
        self.layers = {}
        self.num_layers = 1
        self.weights = {}
        self.biases = {}

        self.epoch_loss = []
        self.epoch_acc = []
        # self.activations = {}

        return None

    def __sigmoid(self, z):

        sigmoid = lambda t: 1/(1 + exp(t))
        gz = np.array([sigmoid(zi) for zi in z])

        # gz = gz.reshape((-1, 1))

        return gz

    def __relu(self, z):

        reLu = lambda t: max(0, t)
        gz = np.array([reLu(zi) for zi in z])

        # gz = gz.reshape((-1, 1))

        return gz

    def __tanh(self, z):
        
        tanh = lambda t: (exp(t) - exp(-t))/(exp(t) + exp(-t))
        gz = np.array([tanh(zi) for zi in z])

        # gz = gz.reshape((-1, 1))

        return gz

    def __softmax(self, x):

        e_sum = 0
        prob = []

        for i in x:
            e_sum += exp(i)
        
        for i in x:
            prob.append(exp(i)/e_sum)

        max_prob = 0
        pred = 0
        for i in range(len(prob)):
            if prob[i] > max_prob:
                max_prob = prob[i]
                pred = i+1

        # print(prob)
        prob = np.array(prob)
        return prob, pred

    def InputLayer(self, input_size):

        self.layers['Input_Layer'] = {'size': input_size}

        return f'<Input Layer: input size={input_size}>'

    def Linear(self, n_neurons=1, activation=None):

        self.layers[f'Layer_{self.num_layers}'] = {'size': n_neurons,
                                                   'neurons': np.zeros(n_neurons),
                                                   'activation': activation
                                                   }
        
        self.num_layers += 1
        
        return f'<Linear Layer: size={n_neurons}, activation={activation}>'

    def Softmax(self, num_classes):

        self.num_classes = num_classes

        self.layers['Output_Layer'] = {'size': num_classes,
                                       'activation': 'softmax'
                                       }

        return f'<Softmax Layer: output size={num_classes}>'

    def __initialize_weights(self, in_shape, out_shape):
        
        layer_weights = []

        if self.params == 'random':
            mean = np.zeros(out_shape)
            cov = np.identity(out_shape)

            layer_weights = np.random.multivariate_normal(mean=mean, cov=cov, size=in_shape)

            # self.weights.append(layer_weights)

        else:
            layer_weights = np.full((in_shape, out_shape), self.params)
            # self.weights.append(layer_weights)

        return layer_weights

    def __initialize_bias(self, out_shape):

        # print('1')

        layer_bias = np.zeros(out_shape)
        # self.biases.append(layer_bias)

        return layer_bias

    def Sequential(self, layers):
        self.layer_info = layers

        # print(self.__layer_n_neurons)

        # for i in range(len(self.layers)-2):
        #     in_shape = self.__layer_n_neurons[i]
        #     out_shape = self.__layer_n_neurons[i+1]
        #     self.__initialize_weights(in_shape, out_shape)
        #     self.__initialize_bias(out_shape)


        keys = list(self.layers.keys())
        for i in range (0, len(keys)-1):
            in_shape = self.layers[keys[i]]['size']
            out_shape = self.layers[keys[i+1]]['size']
            self.weights[f'Weight_{i+1}'] = self.__initialize_weights(in_shape, out_shape)
            self.biases[f'Bias_{i+1}'] = self.__initialize_bias(out_shape)

        return self

    def __forward(self, x, layer):

        W = self.weights[f'Weight_{layer}']
        b = self.biases[f'Bias_{layer}']

        x = np.dot(x, W) + b


        if self.layers[f'Layer_{layer}']['activation']:
            if self.layers[f'Layer_{layer}']['activation'] == 'sigmoid':
                x = self.__sigmoid(x)
            elif self.layers[f'Layer_{layer}']['activation'] == 'relu':
                x = self.__relu(x)
            elif self.layers[f'Layer_{layer}']['activation'] == 'tanh':
                x = self.__tanh(x)

        return x

    def __forward_propagate(self, x):
        
        for i in range(1, self.num_layers):
            x = self.__forward(x, i)
            self.layers[f'Layer_{i}']['neurons'] = x

        W = self.weights[f'Weight_{self.num_layers}']
        b = self.biases[f'Bias_{self.num_layers}']

        x = np.dot(x, W) + b
        x, pred = self.__softmax(x)
        self.layers['Output_Layer']['neurons'] = x
        
        return x, pred
   
    def __calc_error(self, x, y):
        #multi class cross entropy
        # self.loss = -np.sum(np.log(self.prob))
        del_arr = np.subtract(x, y)
        # loss = np.sum(del_arr)

        loss=0
        for i in range(x.size):
            if y[i] == 0:
                loss = loss
            else:
                loss -= math.log(x[i], 10)

        # print(self.probs)
        # print(np.log(self.probs))
        return del_arr, loss

    def __accuracy(self, prediction, train_y):

        correct = 0
        for i in range(prediction.size):
            if prediction[i] == train_y[i]:
                correct +=1

        acc = correct/train_y.size

        return acc

    def __anti_activations(self, z, activ):

        antiz = []

        for i in z:
            if activ:
                if activ=='sigmoid':
                    antiz.append(i*(1-i))

                elif activ=='relu':
                    if i>0:
                        antiz.append(1)
                    else:
                        antiz.append(0)

                elif activ=='tanh':
                    antiz.append(1-i**2)
                
            else:
                antiz.append(1)

        return np.array(antiz)

    def __back_propagation(self, del_arr, y):

        delta = del_arr
        count=0
        
        layers = list(self.layers.keys())
        for i in range(self.num_layers, 0, -1):
            # print(delta)
            weights_cache = self.weights[f'Weight_{i}']

            self.weights[f'Weight_{i}'] = self.weights[f'Weight_{i}'] - self.alpha*(np.dot(delta.transpose(), self.layers[layers[i]]['neurons']))
            self.biases[f'Bias_{i}'] = self.biases[f'Bias_{i}'] - self.alpha*(delta)

            if i>1:
                # delta = np.multiply(np.dot(self.weights[f'Weight_{i}'], delta.transpose()), self.__anti_activations(self.layers[layers[i-1]]['neurons'], self.layers[layers[i-1]]['activation']))
                delta = np.multiply(np.dot(weights_cache, delta.transpose()), self.__anti_activations(self.layers[layers[i-1]]['neurons'], self.layers[layers[i-1]]['activation']))

        return None

    def train(self):
        output = []
        loss_arr = []
        
        for i in range(len(self.train_x)):
            x = self.train_x[i]
            y = self.enc_trainy[i]
            # print(self.__forward_propagate(x))
            x, pred = self.__forward_propagate(x)
            output.append(pred)

            # print(x)

            # print(x, y, pred)
            # self.probs.append(prob)
            del_arr, loss = self.__calc_error(x, y)
            loss_arr.append(loss)

            self.__back_propagation(del_arr, y)

        loss = sum(loss_arr)/self.train_y.size
        # self.epoch_loss.append(loss)

        output = np.array(output)
        train_acc = self.__accuracy(output, self.train_y)
        # self.epoch_acc.append(train_acc)

        # # print(self.out)
        #     self.__loss()

        #     # print(self.loss)

        return loss, train_acc

    def __encode_labels(self):
        enc_labels = np.zeros((self.train_y.size, self.num_classes))

        for i in range(self.train_y.size):
            enc_labels[i][self.train_y[i]-1] = 1

        return enc_labels

    def fit(self, train_x, train_y):
        self.train_x = train_x
        self.train_y = train_y
        self.enc_trainy = self.__encode_labels()

        for i in range(1, self.epochs+1):
            st = time.time()
            print(f'Epoch {i} ====>', end='')
            loss, train_acc = self.train()

            self.epoch_loss.append(loss)
            self.epoch_acc.append(train_acc)

            et = time.time()
            elapsed = et - st

            print(f'Total Loss: {loss}           Train Accuracy: {train_acc*100}%            Time Required: {elapsed}s')

        return self.epoch_loss, self.epoch_acc

    def test(self, test_x, test_y):
        
        pred_labels = []

        for i in test_x:
            x, pred = self.__forward_propagate(i)
            pred_labels.append(pred)

        pred_labels = np.array(pred_labels)

        accuracy = self.__accuracy(pred_labels, test_y)

        return pred_labels.transpose(), accuracy*100
    
    def save(self):
        return (self.weights, self.biases)

    def load(self, model):
        self.weights = model[0]
        self.biases = model[1]

        return self

# print(nn.layer_info)
# print(nn.layers)
# print(nn.weights)
# print(nn.biases)

"""### ***3. Now experiment with different activation functions (at least 3 & to be written from scratch) and comment (in the report) on how the accuracy varies. Create plots to support your arguments.***"""

import matplotlib.pyplot as plt

epochs = 100

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(5, 'relu'),
                       nn.Softmax(3)])

relu_losses, relu_accs = model.fit(train_ax, train_ay)
relu_predictions, relu_test_acc = model.test(test_ax, test_ay)

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model2 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(5, 'tanh'),
                       nn.Softmax(3)])

tanh_losses, tanh_accs = model2.fit(train_ax, train_ay)
tanh_predictions, tanh_test_acc = model2.test(test_ax, test_ay)

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model3 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(5, 'sigmoid'),
                       nn.Softmax(3)])

sigm_losses, sigm_accs = model3.fit(train_ax, train_ay)
sigm_predictions, sigm_test_acc = model3.test(test_ax, test_ay)

plt.plot([i for i in range(1, epochs+1)], [i*100 for i in relu_accs])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in tanh_accs])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in sigm_accs])
plt.xlabel("No. of Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy for different activations")
plt.legend(['relu', 'tanh', 'sigmoid'])
plt.show()

plt.plot([i for i in range(1, epochs+1)], [i for i in relu_losses])
plt.plot([i for i in range(1, epochs+1)], [i for i in tanh_losses])
plt.plot([i for i in range(1, epochs+1)], [i for i in sigm_losses])
plt.xlabel("No. of Epochs")
plt.ylabel("Loss")
plt.title("Loss for different activations")
plt.legend(['relu', 'tanh', 'sigmoid'])
plt.show()

"""### ***4. Experiment with different weight initialization: Random, Zero & Constant. Create plots to support your arguments.***"""

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model4 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(5, 'tanh'),
                       nn.Softmax(3)])

ran_losses, ran_accs = model4.fit(train_ax, train_ay)
ran_predictions, ran_test_acc = model4.test(test_ax, test_ay)
print(f'Test Accuracy: {ran_test_acc}')

nn = NN(params=0, learning_rate=0.001, epochs=epochs)
model5 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(5, 'tanh'),
                       nn.Softmax(3)])

zero_losses, zero_accs = model5.fit(train_ax, train_ay)
zero_predictions, zero_test_acc = model5.test(test_ax, test_ay)
print(f'Test Accuracy: {zero_test_acc}')

nn = NN(params=2, learning_rate=0.001, epochs=epochs)
model6 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(5, 'tanh'),
                       nn.Softmax(3)])

const_losses, const_accs = model6.fit(train_ax, train_ay)
const_predictions, const_test_acc = model6.test(test_ax, test_ay)
print(f'Test Accuracy: {const_test_acc}')

plt.plot([i for i in range(1, epochs+1)], [i*100 for i in ran_accs])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in zero_accs])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in const_accs])
plt.xlabel("No. of Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy for different activations")
plt.legend(['random', 'zero', 'constant 2'])
plt.show()

plt.plot([i for i in range(1, epochs+1)], [i*100 for i in ran_losses])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in zero_losses])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in const_losses])
plt.xlabel("No. of Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy for different activations")
plt.legend(['random', 'zero', 'constant 2'])
plt.show()

"""### ***5. Change the number of hidden nodes and comment upon the training and accuracy. Create plots to support your arguments.Add a provision to save and load weights in the MLP.***"""

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model7 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(8, 'relu'),
                       nn.Linear(5, 'relu'),
                       nn.Softmax(3)])

h1_losses, h1_accs = model7.fit(train_ax, train_ay)
h1_predictions, h1_test_acc = model7.test(test_ax, test_ay)
print(f'Test Accuracy: {h1_test_acc}')

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model8 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(8, 'relu'),
                    #    nn.Linear(5, 'relu'),
                       nn.Softmax(3)])

h2_losses, h2_accs = model8.fit(train_ax, train_ay)
h2_predictions, h2_test_acc = model8.test(test_ax, test_ay)
print(f'Test Accuracy: {h2_test_acc}')

nn = NN(params='random', learning_rate=0.001, epochs=epochs)
model9 = nn.Sequential([nn.InputLayer(10),
                       nn.Linear(8, 'relu'),
                       nn.Linear(4, 'relu'),
                       nn.Softmax(3)])

h3_losses, h3_accs = model9.fit(train_ax, train_ay)
h3_predictions, h3_test_acc = model9.test(test_ax, test_ay)
print(f'Test Accuracy: {h3_test_acc}')

plt.plot([i for i in range(1, epochs+1)], [i*100 for i in h1_accs])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in h2_accs])
plt.plot([i for i in range(1, epochs+1)], [i*100 for i in h3_accs])
plt.xlabel("No. of Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy for different hidden nodes")
# plt.legend(['random', 'zero', 'constant 2'])
plt.show()

plt.plot([i for i in range(1, epochs+1)], [i for i in h1_losses])
plt.plot([i for i in range(1, epochs+1)], [i for i in h2_losses])
plt.plot([i for i in range(1, epochs+1)], [i for i in h3_losses])
plt.xlabel("No. of Epochs")
plt.ylabel("Loss")
plt.title("Loss for hidden nodes")
plt.legend(['relu', 'tanh', 'sigmoid'])
plt.show()

"""# ***Question 03***


---



---
## ***Experiment with Architecture***

## ***A. Google PlayGround***

---

a. If the model is underfitting then increasing the size of the network will help but if the model is working fine then it may start overfitting on increase in size and will lead to a bad model.
Change in convergence on increasing size depends on factors such as the type of dataset being used and also the number of training examples. Therefore, it is variable and cannot be said to only fasten or slow down the convergence in all cases.

c. The best model was obtained with two hidden layers (3 neurons in first layer and 2 neurons in second layer). Activation was kept ReLU, the model was working well with tanh too but minmum loss was obtained with ReLU. Also regularization was kept to be L1. The minimum loss obtained was 0.119 for train and 0.162 for test. The test loss was around 0.01 higher along with the difference in loss in train and test being higher in case of L2 regularization and so L1 was chosen. The training surface had blunt edges.

## ***B. Neural Nets V2 Desmos Visualized***

---

The model was more prone to changes at higher learning rates and the decision boundary changed very quickly with number of iterations. But in case of smaller learning rate the decision boundary changed very slowly and with learning rate less than 0.1 it seemed to be almost constant initially. Thus the training stability decreased with increase in learning rate as the model became more prone to changes with given inputs.

b. Each model converged in around 80-120 steps. The shape of convergence was similar in all the trials but in some trials the error vale increased slightly after achieving minimum while in some it remained on an almost constant trend.
Added one more layer with a single node and also added an extra node to pre-existing hidden layer. In this case, the train loss decreased quickly at first and then remained constant while the test loss decreased a little bit and after hitting a minimum (which was still significantly more than the train loss at that epoch), increased significantly.
"""